{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "\n",
    "## Claim: the data preprocessing part is from https://www.kaggle.com/code/pavansanagapati/a-simple-cnn-model-beginner-guide/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is from https://www.kaggle.com/code/pankajj/fashion-mnist-with-pytorch-93-accuracy\n",
    "\n",
    "class Data(Dataset):\n",
    "    \n",
    "    def __init__(self, data, transform = None):\n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "             # first column is of labels.\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:])\n",
    "        self.labels = np.asarray(label)\n",
    "        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "test_csv = pd.read_csv(\"fashion-mnist_test.csv\")\n",
    "\n",
    "train_data = Data(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_data = Data(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "batch_size = 256\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From now on, we start to build our model\n",
    "# We are also really big sad that we can't use maxpool inside sequential\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # image shape is 28 * 28 * 1, where 1 is one color channel\n",
    "        # 28 * 28 is the image size\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        # output shape = (28 - 3 + 1) * (28 - 3 + 1) * 3 = 26 * 26 * 32\n",
    "        # maxpooling\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # output shape = 13 * 13 * 32\n",
    "        # Note the volumn depth is not changed\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=4)\n",
    "        # output shape = (13 - 4 + 1) * (13 - 4 + 1) * 64 = 10 * 10 * 16\n",
    "        # maxpooling\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # output shape = 10 * 10 * 16\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # fully connected layer\n",
    "        self.fc1 = nn.Linear(10 * 10 * 16, 600)\n",
    "        self.fc2 = nn.Linear(600, 120)\n",
    "        self.fc3 = nn.Linear(120, 10)\n",
    "        self.initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # first conv\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        # flatten all dimensions except batch\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ConvNet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/75 [00:05<06:54,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train accuracy: 10.0%, Avg loss:      nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/75 [00:11<06:40,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train accuracy: 10.0%, Avg loss:      nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/75 [00:16<06:33,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train accuracy: 10.0%, Avg loss:      nan\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "epoches = 75\n",
    "lost = []\n",
    "for epoch in tqdm(range(epoches)):\n",
    "    train_loss, correct = 0, 0\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "\n",
    "        loss = loss_fn(pred, y.long())\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # record loss\n",
    "        train_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    size = len(train_dataloader.dataset)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    correct /= size\n",
    "    print(f\" Train accuracy: {(100*correct):>0.1f}%, Avg loss: {train_loss:>8f}\")\n",
    "    lost.append(train_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
